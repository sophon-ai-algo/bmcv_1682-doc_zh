

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>AutoSplit &mdash; SophonInference  documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="SophonInference  documentation" href="../index.html"/>
        <link rel="next" title="AutoRunner" href="autorunner.html"/>
        <link rel="prev" title="SAIL" href="sail.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> SophonInference
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../quickstart/abstract.html">图解 Sophon Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart/install.html">Sophon Inference 编译</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../demo/preparation.html">前言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demo/cpp.html">C++ Samples Using BMNNSDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demo/cpp_sail.html">C++ Samples Using SAIL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demo/python.html">Python Samples (Algokit)</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="sail.html">SAIL</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">AutoSplit</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#graph-infos-json">graph_infos.json</a></li>
<li class="toctree-l2"><a class="reference internal" href="#split">split</a></li>
<li class="toctree-l2"><a class="reference internal" href="#convert">convert</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="autorunner.html">AutoRunner</a></li>
<li class="toctree-l1"><a class="reference internal" href="algokit.html">Algokit</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">SophonInference</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
    <li>AutoSplit</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/module/autosplit.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="autosplit">
<h1>AutoSplit<a class="headerlink" href="#autosplit" title="Permalink to this headline">¶</a></h1>
<p>AutoSplit 是一个一键式的离线模型自动切分与编译工具。
对于一个无法完整部署到 TPU 上的模型，AutoSplit 可以自动化地将其切分为一系列子模型，
并可以调用 BMCompiler 将其中部分可以部署到 TPU 上的子模型编译为 bmodel，例如下图的 fasterrcnn 模型。</p>
<img alt="../_images/autodeploy.png" src="../_images/autodeploy.png" />
<p>用户无须关心模型的切分细节与如何编译生成 bmodel，生成的子模型可以用 auto_runner 中提供的接口进行推理。
AutoSplit 源码位于 “module/auto_split/” 目录下，目前支持 tensorflow/mxnet。
我们在 “auto_split.api” 中提供了两个函数，它们分别是：</p>
<ul class="simple">
<li>split：</li>
</ul>
<p>将需要部署的模型自动切分成若干子模型，
把子模型保存至指定目录并将相关参数保存至目录下的 graph_infos.json 文件中。</p>
<ul class="simple">
<li>convert：</li>
</ul>
<p>解析指定目录下的 graph_infos.json 文件，将目录下所有可在 TPU 上部署的模型编译为 bmodel。</p>
<div class="section" id="graph-infos-json">
<h2>graph_infos.json<a class="headerlink" href="#graph-infos-json" title="Permalink to this headline">¶</a></h2>
<img alt="../_images/split.png" src="../_images/split.png" />
<p>AutoSplit 可以将模型自动切分为多个子模型，
因此我们定义了一种保存切分后的子模型的方式。
上图展示了将 tensorflow detection model zoo 中的
ssd_mobilenet_v2_coco_2018_03_29
(<a class="reference external" href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz">http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz</a>)
拆分后生成的子模型。</p>
<p>图中的 “graph_0.pb”、“graph_1.pb”、“graph_2.pb” 是拆分后生成三个子模型，
它们是经过拓扑排序的，也就是说给定输入，顺序执行这三个子模型，
输出的结果跟原始未切分的模型是一致的。</p>
<p>图中的 compile_to_graph_ir_1.py 脚本通过调用 BMCompiler(bmnett)
将 graph_1.pb 编译成 bmodel 并保存在 graph_ir_1/ 中。</p>
<p>graph_infos.json 文件中包含了子模型的信息。
包括：</p>
<ul class="simple">
<li>graphs：</li>
</ul>
<p>一个列表，其中每个元素中都包含了一个子模型的 “输入名称(inputs)”、“输出名称(outputs)”、“运行设备(cpu或tpu)”、“模型路径信息(model_info)”，
如果运行设备为 tpu，那么还会包含 bmodel 所在的路径(context_dir)。</p>
<ul class="simple">
<li>tensors：</li>
</ul>
<p>包含了所有子模型的输入和输出张量的信息，这些张量分为三类：“input”、“output”、“intermediate”，
其中 “input”、“output” 表示该张量是原始模型的输入输出，而 “intermediate” 表示该张量是切分后产生的中间张量。</p>
<ul class="simple">
<li>graph_num：</li>
</ul>
<p>切分后子模型的数量。</p>
<ul class="simple">
<li>platform：</li>
</ul>
<p>原始模型所基于的深度学习框架，目前支持 tensorflow 和 mxnet。</p>
<ul class="simple">
<li>dynamic：</li>
</ul>
<p>动态代表模型的输入张量是尺寸是可变的，如果是动态的，那么 tensors 中的尺寸信息为最大的尺寸。</p>
<ul class="simple">
<li>layout：</li>
</ul>
<p>原始模型的 layout，NHWC 或者 NCHW。</p>
<p>下面展示了上图中的 graph_infos.json 中的内容：</p>
<blockquote>
<div><div class="highlight-json"><div class="highlight"><pre><span class="p">{</span>
  <span class="nt">&quot;graphs&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="nt">&quot;outputs&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;Preprocessor/map/TensorArrayStack/TensorArrayGatherV3:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/zeros_like_1:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/div_1:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/div:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/zeros_like:0&quot;</span>
       <span class="p">],</span>
      <span class="nt">&quot;model_info&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;model_path&quot;</span><span class="p">:</span> <span class="s2">&quot;graph_0.pb&quot;</span>
      <span class="p">},</span>
      <span class="nt">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;image_tensor:0&quot;</span>
      <span class="p">],</span>
      <span class="nt">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span>
    <span class="p">},</span>
    <span class="p">{</span>
      <span class="nt">&quot;outputs&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;Squeeze:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/convert_scores:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/Reshape_1:0&quot;</span>
      <span class="p">],</span>
      <span class="nt">&quot;model_info&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;model_path&quot;</span><span class="p">:</span> <span class="s2">&quot;graph_1.pb&quot;</span>
      <span class="p">},</span>
      <span class="nt">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;Preprocessor/map/TensorArrayStack/TensorArrayGatherV3:0&quot;</span>
      <span class="p">],</span>
      <span class="nt">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;tpu&quot;</span><span class="p">,</span>
      <span class="nt">&quot;context_dir&quot;</span><span class="p">:</span> <span class="s2">&quot;graph_ir_1&quot;</span>
    <span class="p">},</span>
    <span class="p">{</span>
      <span class="nt">&quot;outputs&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;detection_boxes:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;num_detections:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;detection_classes:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;detection_scores:0&quot;</span>
      <span class="p">],</span>
      <span class="nt">&quot;model_info&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;model_path&quot;</span><span class="p">:</span> <span class="s2">&quot;graph_2.pb&quot;</span>
      <span class="p">},</span>
      <span class="nt">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;Postprocessor/div:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Squeeze:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/convert_scores:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/zeros_like_1:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/zeros_like:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/div_1:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/Reshape_1:0&quot;</span>
      <span class="p">],</span>
      <span class="nt">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span>
    <span class="p">}</span>
  <span class="p">],</span>
  <span class="nt">&quot;tensors&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&quot;Postprocessor/div:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;Squeeze:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1917</span><span class="p">,</span>
        <span class="mi">4</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;Postprocessor/convert_scores:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1917</span><span class="p">,</span>
        <span class="mi">91</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;Postprocessor/zeros_like_1:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;num_detections:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;output&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;Postprocessor/zeros_like:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;detection_classes:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">100</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;output&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;detection_boxes:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">100</span><span class="p">,</span>
        <span class="mi">4</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;output&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;Postprocessor/div_1:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;detection_scores:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">100</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;output&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;Preprocessor/map/TensorArrayStack/TensorArrayGatherV3:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">300</span><span class="p">,</span>
        <span class="mi">300</span><span class="p">,</span>
        <span class="mi">3</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;image_tensor:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">500</span><span class="p">,</span>
        <span class="mi">500</span><span class="p">,</span>
        <span class="mi">3</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;input&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;Postprocessor/Reshape_1:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1917</span><span class="p">,</span>
        <span class="mi">4</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">}</span>
  <span class="p">},</span>
  <span class="nt">&quot;graph_num&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
  <span class="nt">&quot;platform&quot;</span><span class="p">:</span> <span class="s2">&quot;tensorflow&quot;</span><span class="p">,</span>
  <span class="nt">&quot;dynamic&quot;</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
  <span class="nt">&quot;layout&quot;</span><span class="p">:</span> <span class="s2">&quot;NHWC&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="split">
<h2>split<a class="headerlink" href="#split" title="Permalink to this headline">¶</a></h2>
<p>该函数可以将无法完整部署在 TPU 上的深度学习模型自动切分为若干子模型。
主要功能通过 <strong>Splitter</strong> 类实现，我们在基类 <strong>Splitter</strong> 中定义了模型切分的流程，
任何子类在实现了一系列的虚函数(例如判断某个 op 是否是支持的 is_op_support)后，
通过调用 <strong>convert_and_split</strong> 函数可完成模型切分。
切分的算法是各个子类共用的，实现在 <strong>auto_deploy.common.graph</strong> 模块中。</p>
<p><strong>split</strong> 函数说明如下，
如果您想了解模型切分的细节，或者需要实现一个新的 Splitter，
可以参考模块： <strong>auto_deploy.common.base_splitter</strong> 、 <strong>auto_deploy.common.graph</strong> 、 <strong>auto_deploy.splitter</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="nd">@exception_wrapper</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;Met an Error when split model.&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="n">platform</span><span class="p">,</span> <span class="n">input_tensors</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">,</span> <span class="n">graph_path</span><span class="p">,</span> \
          <span class="n">params_path</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">dynamic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="s1">&#39;NCHW&#39;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Split the raw model into several submodels.</span>

<span class="sd">  Args:</span>
<span class="sd">    platform: Platform that trained the model.</span>
<span class="sd">              Options: tensorflow, mxnet, pytorch, caffe</span>
<span class="sd">    input_tensors: A dict contains the information of input tensors.</span>
<span class="sd">                  Format: {input_name: numpy.ndarray}</span>
<span class="sd">    save_dir: Path of directory to save submodels and splitting information.</span>
<span class="sd">    graph_path: Path to the graph description file of the model.</span>
<span class="sd">    params_path: Path to the parameters file of the model. Default None.</span>
<span class="sd">    outputs: A list contains the output tensor names. Default None.</span>
<span class="sd">    dynamic: True means input tensor shapes may change. Default False.</span>
<span class="sd">    layout: Layout of tensor. Default &#39;NCHW&#39;.</span>

<span class="sd">  Returns:</span>
<span class="sd">    None.</span>
<span class="sd">  &quot;&quot;&quot;</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="convert">
<h2>convert<a class="headerlink" href="#convert" title="Permalink to this headline">¶</a></h2>
<p>该函数可以将切分后的模型中的可以在 TPU 上运行的模型编译成 bmodel，
其依据是 graph_infos.json 文件中每个 graph 中的 device。
如果 device 是 tpu，那么会调用对应深度学习框架下的 BMCompiler 对模型进行编译。
功能通过 Compiler 类实现，每个子类需封装对应深度学习框架下的 BMCompiler。</p>
<p><strong>convert</strong> 函数说明如下，详见模块： <strong>auto_deploy.common.base_compiler</strong> 和 <strong>auto_deploy.compiler</strong> 。</p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="nd">@exception_wrapper</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;Met an Error when compile model.&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">convert</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">optimize</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">compare</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;BM1682&#39;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Compile all the subgraphs which can deploy on sophon.</span>

<span class="sd">  Args:</span>
<span class="sd">    folder: path that contains splitted models,</span>
<span class="sd">            &#39;graph_infos.json&#39; must be under this folder</span>

<span class="sd">    Format of &#39;graph_infos.json&#39;:</span>
<span class="sd">    {</span>
<span class="sd">      &quot;graph_num&quot;: graph_numbmer,</span>
<span class="sd">      &quot;platform&quot;: &quot;mxnet&quot;</span>
<span class="sd">      &quot;layout&quot;: &quot;NCHW&quot;</span>
<span class="sd">      &quot;dynamic&quot;: False</span>
<span class="sd">      &quot;graphs&quot;: [</span>
<span class="sd">        {</span>
<span class="sd">          &quot;device&quot;: &quot;cpu&quot;,</span>
<span class="sd">          &quot;inputs&quot;: list of input tensor names,</span>
<span class="sd">          &quot;outputs&quot;: list of output tensor names,</span>
<span class="sd">          &quot;model_info&quot;: {</span>
<span class="sd">            &quot;json&quot;: json_file_path,</span>
<span class="sd">            &quot;params&quot;: params_file_path</span>
<span class="sd">          }</span>
<span class="sd">        }</span>
<span class="sd">      ]</span>
<span class="sd">      &quot;tensors&quot;: [</span>
<span class="sd">        {</span>
<span class="sd">          &quot;name&quot;: name,</span>
<span class="sd">          &quot;shape&quot;: list for shape,</span>
<span class="sd">          &quot;attr&quot;: &quot;input&quot; or &quot;output&quot; or &quot;intermediate&quot;</span>
<span class="sd">        }</span>
<span class="sd">      ]</span>
<span class="sd">    }</span>
<span class="sd">    optimize: optimizing mode, parameter of bmnet compiler.</span>
<span class="sd">    compare: if compare with cpu results when compiling.</span>
<span class="sd">    target: &#39;BM1682&#39; or &#39;BM1684&#39;(future).</span>

<span class="sd">  Returns: None.</span>
<span class="sd">  &quot;&quot;&quot;</span>
</pre></div>
</div>
</div></blockquote>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="autorunner.html" class="btn btn-neutral float-right" title="AutoRunner" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="sail.html" class="btn btn-neutral" title="SAIL" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Sophon.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>