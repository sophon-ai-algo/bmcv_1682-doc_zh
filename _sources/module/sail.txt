SAIL
====

SAIL 是 Sophon Inference 中的支撑模块，
AutoDeploy、Algokit 以及 Samples 中的大部分代码都建立在 SAIL 的基础上。

SAIL 对 BMNNSDK 中的 BMRuntime、BMCV、BMDecoder 进行了封装，
将 BMNNSDK 中原有的 “加载 bmodel 并驱动 TPU 推理”、
“驱动 TPU 做图像处理”、“驱动 VPU 做图像和视频解码” 
等功能抽象成更为简单的 C++ 接口对外提供；
并且支持使用 pybind11 再次封装，
提供了最为简洁的 python 接口。

目前，SAIL 模块中所有的类、枚举、函数都在 “sail” 名字空间下，
本单元中的文档将深入介绍您可能用到的 SAIL 中的模块和类。
核心的类包括：

* Engine：

BMRuntime 的包装类，可以加载 bmodel 并驱动 TPU 进行推理。
一个 Engine 示例可以加载一个任意的 bmodel，
自动地管理输入张量与输出张量对应的内存。

* Frame：

封装了 Ffmpeg 中 的AVFrame，该 Ffmpeg 库是 Bitmain 提供的，与 BMNNSDK 一起发布，
用于驱动 Sophon 深度学习加速卡上的 VPU 进行视频解码。

* VideoDecoder：

将驱动 VPU 进行视频解码的功能进行了封装。

* Bmcv：

封装了一系列的图像处理函数，可以驱动 TPU 进行图像处理。

除此之外，由于我们目前提供了较多计算机视觉领域的模型部署例程，
因此我们还对常用分类、检测等模型的前处理和后处理也进行了封装。
分别实现为 Preprocess、Postprocess 两个模块，
使用方法可以参考第二章中介绍的相关示例程序。

Engine
______

**1). Engine 构造函数**

    .. code-block:: c++

        @brief Constructor using default input shapes.

        @param context_dir Context directory path generated by BMCompiler
        @param chip_name   Name of the hardware. Option: "BM1682_PCIE",
                           "BM1682_SOC", "BM1684_PCIE", "BM1684_SOC"
        @param tpus        Ids of TPUS to be used, split by comma. Eg.: "0,1" for
                           TPU 0 and TPU 1, "all" for all available TPUs
        @param mode        Specify the input/output tensors are in system memory
                           or device memory
        @param dynamic     True for dynamic models and false for static ones
        
        Engine(
            const std::string& context_dir,
            const std::string& chip_name,
            const std::string& tpus,
            IOMode             mode,
            bool               dynamic);


**2). get_graph_names**

    .. code-block:: c++

       @brief Get all graph names in the loaded context.
 
       @return All graph names
   
       std::vector<std::string> get_graph_names();

**3). get_input_names**

    .. code-block:: c++

       @brief Get all input tensor names of the specified graph.
   
       @param graph_name The specified graph name
       @return All the input tensor names of the graph
   
       std::vector<std::string> get_input_names(const std::string& graph_name);

**4). get_output_names**

    .. code-block:: c++

       @brief Get all output tensor names of the specified graph.

       @param graph_name The specified graph name
       @return All the output tensor names of the graph
   
       std::vector<std::string> get_output_names(const std::string& graph_name);

**5). is_input_batch_size_equal**

    .. code-block:: c++

       @brief Judge if batch size of all input tensors are equal.
   
       @param input_shapes All input tensor shapes
       @batch_size         Batch size to return
   
       @return True if batch size of all input tensors are equal
   
       bool is_input_batch_size_equal(
           std::map<std::string, std::vector<int>>& input_shapes,
           int&                                     batch_size);

**6). set_input_shape**

    .. code-block:: c++

       @brief Set input tensor shapes when running dynamic models with
              synchronous mode.
   
       The input tensor shapes may change between batches when running dynamic
       models. New input shapes should be set before inference. Note that this
       function is for synchronous mode.
  
       @param graph_name   The specified graph name
       @param input_shapes Specified shapes of all input tensors of the graph
   
       void set_input_shape(
           const std::string&                       graph_name,
           std::map<std::string, std::vector<int>>& input_shapes);

**7). get_bmrt**

    .. code-block:: c++

       @brief Get bmruntime pointers created by constructor.
   
       @return bmruntime pointers
   
       BmRuntime get_bmrt();

**8). get_max_input_shapes**

    .. code-block:: c++

       @brief Get max shapes of input tensors in a graph.
   
       For static models, the max shape is the static shape and it should not be
       changed. While for dynamic models, the tensor shape should be smaller than
       or equal to the max shape.
   
       @param graph_name The specified graph name
       @param is_total   True for total specified tpus; False for a single one
       @return The max shape of the tensor
   
       std::map<std::string, std::vector<int>> get_max_input_shapes(
           const std::string& graph_name,
           bool               is_total);

**9). get_input_shape**

    .. code-block:: c++

       @brief Get the shape of an input tensor in a graph.
   
       @param graph_name  The specified graph name
       @param tensor_name The specified tensor name
       @return The shape of the tensor
   
       std::vector<int> get_input_shape(
           const std::string& graph_name,
           const std::string& tensor_name);

**10). get_output_shape**

    .. code-block:: c++

       @brief Get the shape of an output tensor in a graph.
  
       @param graph_name  The specified graph name
       @param tensor_name The specified tensor name
       @return The shape of the tensor
   
       std::vector<int> get_output_shape(
           const std::string& graph_name,
           const std::string& tensor_name);

**11). get_input_tensor_sys**

    .. code-block:: c++

       @brief Get the data pointer in the system memory of the input tensor.
   
       @param graph_name  The specified graph name
       @param tensor_name The specified tensor name
       @return The data pointer in the system memory of the input tensor
   
       Dtype* get_input_tensor_sys(
           const std::string& graph_name,
           const std::string& tensor_name);

**12). get_output_tensor_sys**

    .. code-block:: c++

       @brief Get the data pointer in the system memory of the output tensor.
   
       @param graph_name  The specified graph name
       @param tensor_name The specified tensor name
       @return The data pointer in the system memory of the output tensor
       @note It's static models or synchronous mode
   
       Dtype* get_output_tensor_sys(
           const std::string& graph_name,
           const std::string& tensor_name);

**13). get_input_tensor_dev_mem**

    .. code-block:: c++

       @brief Get the device memory of the input tensor with synchronous mode.
   
       @param graph_name  The specified graph name
       @param tensor_name The specified tensor name
       @return The device memory of the input tensor
   
       bm_device_mem_t* get_input_tensor_dev_mem(
           const std::string& graph_name,
           const std::string& tensor_name);

**14). get_input_tensor_dev**

    .. code-block:: c++

       @brief Get the input tensor which only owns the device memory with
              synchronous mode.
   
       @param graph_name  The specified graph name
       @param tensor_name The specified tensor name
       @return A Tensor instance which only owns the device memory of the tensor.
   
       Tensor<Dtype> get_input_tensor_dev(
           const std::string& graph_name,
           const std::string& tensor_name);

**15). get_output_tensor_dev_mem**

    .. code-block:: c++

       @brief Get the device memory of the output tensor with synchronous mode.
   
       @param graph_name  The specified graph name
       @param tensor_name The specified tensor name
       @return The device memory of the output tensor
   
       bm_device_mem_t* get_output_tensor_dev_mem(
           const std::string& graph_name,
           const std::string& tensor_name);

**16). get_output_tensor_dev**

    .. code-block:: c++

       @brief Get the output tensor which only owns the device memory with
              synchronous mode.
   
       @param graph_name  The specified graph name
       @param tensor_name The specified tensor name
       @return A Tensor instance which only owns the device memory of the tensor.
   
       Tensor<Dtype> get_output_tensor_dev(
           const std::string& graph_name,
           const std::string& tensor_name);

**17). process**

    .. code-block:: c++

       @brief Do inference with synchronous mode.
   
       @param graph_name The specified graph name
   
       void process(const std::string& graph_name);



       @brief Do inference with synchronous mode with provided input tensors
   
       @param graph_name The specified graph name
       @input_shapes     Shapes of all input tensors
       @input_tensors    Data pointers of all input tensors in system meory
   
       void process(
           const std::string&                       graph_name,
           std::map<std::string, std::vector<int>>& input_shapes,
           std::map<std::string, Dtype*>&           input_tensors);

**18). reset_input_tensors**

    .. code-block:: c++

       @brief Reset data pointers of input tensors in system memory.
   
       @param graph_name    The specified graph name
       @param input_shapes  Shapes of all input tensors
       @param input_tensors Data pointers in system meory for all input tensors
   
       void reset_input_tensors(
           const std::string&                       graph_name,
           std::map<std::string, std::vector<int>>& input_shapes,
           std::map<std::string, Dtype*>&           input_tensors);

Frame
_____

Frame 是对比特大陆定制版的 FFMPEG 中的 AVFrame 数据结构的封装，用于支撑 VPU 硬件解码功能。
Frame 类提供的接口如下。

**1). Frame 构造函数**

    .. code-block:: c++

       @brief Constructor

       Frame();

**2). get**

    .. code-block:: c++

       @brief Get the pointer of AVFrame instance.

       @return Pointer of AVFrame instance.

       AVFrame* get();

**3). get_height**

    .. code-block:: c++

       @brief Get height of the frame.

       @return Height of the frame

       int get_height();

**4). get_width**

    .. code-block:: c++

       @brief Get width of the frame.

       @return Width of the frame

       int get_width();


VideoDecoder
____________

**1). VideoDecoder 构造函数**

    .. code-block:: c++

       @brief Constructor.

       @param file_path Path to the video file.

       explicit VideoDecoder(const std::string& file_path);

**2). is_opened**

    .. code-block:: c++

       @brief Judge if the video file is opened successfully.

       @return True if the video file is opened successfully

       bool is_opened();

**3). get_frame_shape**

    .. code-block:: c++

       @brief Get frame shape in the video.

       @return Frame shape in the video, [1, C, H, W]

       std::vector<int> get_frame_shape();

**4). read**

    .. code-block:: c++

       @brief Read a frame from the video.

       @param frame Reference of frame to be read to
       @return 0 for success and 1 for failure

       int read(Frame& frame);


Bmcv
____

**1). Bmcv 构造函数**

    .. code-block:: c++

       @brief Constructor.

       explicit Bmcv(BmRuntime bmrt) :
         handle_(static_cast<bm_handle_t>(bmrt_get_bm_handle(bmrt.get_ptr()))),
         p_bmrt_(bmrt.get_ptr()) {}

**2). get_bmrt**

    .. code-block:: c++

       @brief Get pointer to bmruntime.

       @return Pointer to bmruntime

       void* get_bmrt();

**3). get_bgr_from_frame**

    .. code-block:: c++

       @brief Get BGR data from a frame read by VPU.

       @param frame  A Frame instance read by VPU
       @param tensor A tensor stores the BGR data

       void get_bgr_from_frame(Frame& frame, Tensor<float>& tensor);

**4). resize**

    .. code-block:: c++

       @brief Resize an image with interpolation of INTER_NEAREST.

       @param input  Input image
       @param output Output image
       @return 0 for success and other for failure

       int resize(
         Tensor<float>&             input,
         Tensor<float>&             output);

**5). crop**

    .. code-block:: c++

       @brief Crop an image.
   
       @param input  Input image
       @param output Output image
       @param top    Start point most top from original image
       @param left   Start point most left from original image
       @return 0 for success and other for failure
   
       int crop(
         Tensor<float>&             input,
         Tensor<float>&             output,
         int                        top,
         int                        left);

**6). yuv2bgr**

    .. code-block:: c++

       @brief Convert an image from YUV to BGR.
  
       @param input_y  Data of channel Y
       @param input_uv Data of Channel UV
       @param ouput    Data of BGR
       @return 0 for success and other for failure
   
       int yuv2bgr(
         Tensor<float>&             input_y,
         Tensor<float>&             input_uv,
         Tensor<float>&             output);

**7). crop_resize_norm**

    .. code-block:: c++

       @brief Resize an image, crop it and do normalizition.
  
       @param input       Input image
       @param output      Output image
       @param top         Start point most top from original image
       @param left        Start point most left from original image
       @param crop_height Crop image height
       @param crop_width  Crop image width
       @param scale_b     Scale factor for channel b
       @param bias_b      Bias for channel b
       @param scale_g     Scale factor for channel g
       @param bias_g      Bias for channel g
       @param scale_r     Scale factor for channel r
       @param bias_r      Bias for channel r
       @return 0 for success and other for failure
   
       int crop_resize_norm(
         Tensor<float>&             input,
         Tensor<float>&             output,
         int                        top,
         int                        left,
         int                        crop_height,
         int                        crop_width,
         float                      scale_b,
         float                      bias_b,
         float                      scale_g,
         float                      bias_g,
         float                      scale_r,
         float                      bias_r);

**8). resize_norm**

    .. code-block:: c++

       @brief Resize an image and do normalizition.
   
       @param input   Input image
       @param output  Output image
       @param scale_b Scale factor for channel b
       @param bias_b  Bias for channel b
       @param scale_g Scale factor for channel g
       @param bias_g  Bias for channel g
       @param scale_r Scale factor for channel r
       @param bias_r  Bias for channel r
       @return 0 for success and other for failure
   
       int resize_norm(
         Tensor<float>&             input,
         Tensor<float>&             output,
         float                      scale_b,
         float                      bias_b,
         float                      scale_g,
         float                      bias_g,
         float                      scale_r,
         float                      bias_r);

**9). transpose**

    .. code-block:: c++

       @brief Transpose an image.
   
       @param input  Input image
       @param output Output image
       @return 0 for success and other for failure
   
       int transpose(
         Tensor<float>&             input,
         Tensor<float>&             output);

**10). bgrsplit**

    .. code-block:: c++

       @brief Convert packed BGR image data to BGR planar data format..
   
       @param input  Input image
       @param output Output image
       @return 0 for success and other for failure
   
       int bgrsplit(
         Tensor<float>&             input,
         Tensor<float>&             output);

